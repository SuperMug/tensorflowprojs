{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snTpu_k9rQer",
        "outputId": "a090fc24-6b4f-49fb-b9cb-5fbfb3ae4b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-11 12:54:37--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  17.0MB/s    in 8.1s    \n",
            "\n",
            "2022-12-11 12:54:46 (9.85 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOBIPk-3rkVu",
        "outputId": "d1d3d35f-f421-4e65-c8ce-a3b39ad5248e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-11 18:23:33.437062: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-11 18:23:36.438583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lucas/miniconda3/lib/\n",
            "2022-12-11 18:23:36.438738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lucas/miniconda3/lib/\n",
            "2022-12-11 18:23:36.438748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100006 files belonging to 1 classes.\n",
            "WARNING:tensorflow:From /home/lucas/miniconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-11 18:23:43.829229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-11 18:23:45.955641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2826 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        }
      ],
      "source": [
        "#Make dataset from data\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "dataset = keras.utils.text_dataset_from_directory(\n",
        "    directory=\"aclImdb\", label_mode=None, batch_size= 256)\n",
        "dataset = dataset.map(lambda x: tf.strings.regex_replace(x, \"<br />\", \" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KjPOSPFusEp6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "sequence_length = 100\n",
        "vocab_size= 15000\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_sequence_length=sequence_length,\n",
        "    output_mode=\"int\"\n",
        ")\n",
        "text_vectorization.adapt(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uJLad_Hssi2-"
      },
      "outputs": [],
      "source": [
        "def prepare_lm_dataset(text_batch):\n",
        "  vectorized_sequences=text_vectorization(text_batch)\n",
        "  x=vectorized_sequences[:, :-1]\n",
        "  y=vectorized_sequences[:, 1:]\n",
        "  return x, y\n",
        "\n",
        "lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ic3sybYdtcn6"
      },
      "outputs": [],
      "source": [
        "#Not using RNN-like architecture because would need N words in each prompt and training sequences would overlap\n",
        "#Therefore, using sequence-to-sequence model!\n",
        "#Use casual masking to make sure that model not cheating during training, and therefore actually learning something\n",
        "\n",
        "#First make layers that needed for relevant architecture\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ao-i_klsu0jg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads=2\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
        "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QW0sCpadv71e"
      },
      "outputs": [],
      "source": [
        "#Augmenting probabilty distribution with variable temperature (introducing randomess to model)\n",
        "#Creates creativity illusion\n",
        "import numpy as np\n",
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "  distribution = np.log(original_distribution) / temperature\n",
        "  distribution = np.exp(distribution)\n",
        "  return distribution / np.sum(distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JplPwEQYwMEp"
      },
      "outputs": [],
      "source": [
        "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "\n",
        "def sample_text(predictions, temperature=1.0):\n",
        "  predictions = np.asarray(predictions).astype(\"float64\")\n",
        "  predictions=np.log(predictions)/temperature\n",
        "  exp_preds= np.exp(predictions)\n",
        "  predictions= exp_preds/ np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, predictions, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "class TextGenerator(keras.callbacks.Callback):\n",
        "  def __init__(\n",
        "      self,\n",
        "      prompt,\n",
        "      generate_length,\n",
        "      model_input_length,\n",
        "      temperatures=(1.0),\n",
        "      print_freq=1):\n",
        "    self.prompt = prompt\n",
        "    self.generate_length= generate_length\n",
        "    self.model_input_length = model_input_length\n",
        "    self.temperatures = temperatures\n",
        "    self.print_freq = print_freq\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if (epoch + 1) % self.print_freq != 0:\n",
        "      return\n",
        "    for temperature in self.temperatures:\n",
        "      print(\" Generating with temp\", temperature)\n",
        "      sentence = self.prompt\n",
        "      for i in range(self.generate_length):\n",
        "        tokenized_sentence = text_vectorization([sentence])\n",
        "        predictions = self.model([tokenized_sentence])\n",
        "        next_token = sample_text(predictions[0, i, :])\n",
        "        sampled_token = tokens_index[next_token]\n",
        "        sentence += \" \" + sampled_token\n",
        "      print(sentence)\n",
        "prompt = \"This movie\"\n",
        "text_gen_callback = TextGenerator(\n",
        "prompt,\n",
        "generate_length=50,\n",
        "model_input_length=sequence_length,\n",
        "temperatures=(0.2, 0.5, 0.6, 0.7, 1., 1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgYaV75l5LQG",
        "outputId": "65ed241b-4795-408c-f565-273a66231b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  6/391 [..............................] - ETA: 2:43 - loss: 4.5098"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1943s vs `on_train_batch_end` time: 0.2235s). Check your callbacks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - ETA: 0s - loss: 4.4678 Generating with temp 0.2\n",
            "This movie movie is all hard right about my ready money medical in students between the the ramones opinions i geek think and people [UNK] how on he dinosaurs knows live why in they [UNK] have  a fight for themselves the love of the matrix theater with i just one of\n",
            " Generating with temp 0.5\n",
            "This movie horror is is an full american vomit horror [UNK] horror horror flicks if and all silence [UNK] youll like dig not this have horror a concerning cheesy freddy fun unless gore you stunningly want lovable to needy fill folks your theres personal good virginity fight energy scenes [UNK] while then\n",
            " Generating with temp 0.6\n",
            "This movie horrific is seated mostly near beautiful the landscapes gate the which country released music it is expanded due somehow to moving [UNK] pictures a that great possessed performances bullets by mixed robert the duvall [UNK] and his mpaa brother d [UNK] a guys [UNK] are f [UNK] kaufman having via\n",
            " Generating with temp 0.7\n",
            "This movie movie was is badly just conceived too about a an [UNK] bored [UNK] score [UNK] that was the made head well talking put animals it in into a making special flick effect the look praise of sounds the like lives film of i two think misses mostly quite it an\n",
            " Generating with temp 1.0\n",
            "This movie movie is is neither technically rather accurate graphic nor for horny the [UNK] cannes rushes cinema since lovers theres preview lots in of this [UNK] movie about imdb [UNK] and or [UNK] on writerdirector it [UNK] maybe failure knows or what act if is he used entitled to may his\n",
            " Generating with temp 1.5\n",
            "This movie really was goes creepy before house the to gore strange is scenes japan all as makes he up more with reasons a than few how there difficult are to there still are some even rich quite rich good in thing transforming to him escape into dying something off otherwise to\n",
            "391/391 [==============================] - 170s 433ms/step - loss: 4.4678\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.3810 Generating with temp 0.2\n",
            "This movie is is simply fabulous done in its his depardieu best and with hopefully hollywood better choice than viewed r quite rated a r score in rated this film evans although also so accounts was do left drugs a and few the years story [UNK] is over certainly and better pryor\n",
            " Generating with temp 0.5\n",
            "This movie is is real an i innocent like pursue kimberly watching sarandon and acting most really of is all most wrong touching i in have love ever tennessee touched williams on and life brings this it is will definitely stand not bravo so to impressive me face i dance strongly is\n",
            " Generating with temp 0.6\n",
            "This movie used has blood been [UNK] done fact by the the camera [UNK] work was of evident the in cinematography the and sound lighting movements was as dreadful silly are as the high lines speech of with the people [UNK] the storyline cotten was in a [UNK] reached staying locations in\n",
            " Generating with temp 0.7\n",
            "This movie movie was was really basically sorry about the a problems plot sandra that bullock was her involved first but off michael an lord aging is star put harvey up in a the story role to that this he is is supposedly a the cool set [UNK] point lifestyles of that\n",
            " Generating with temp 1.0\n",
            "This movie is is like already an peterson absolute leonard long book love written it 3 contains he a 4 rich reel religious 10 stories will religious watch people ranking and also are have given met a and rave [UNK] back movie to glamorous everything and about sarah really miles search and\n",
            " Generating with temp 1.5\n",
            "This movie is is a somewhat personal weak series kevin i brown thought whose it vhs is is an not important stellar theme elton song john time astin period is of covered advertising in berry the [UNK] academy standouts on out which on has reflection for in bill horror a films little\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.3810\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.3146 Generating with temp 0.2\n",
            "This movie is is like just the a movie bit for at me least it those is improv amazing movies as that if cambodia done [UNK] not island as and all sometimes japanese realistic also acting there eg are men campy from plot raging or washington a but movie it just kind\n",
            " Generating with temp 0.5\n",
            "This movie film has has to the be pleasure one to of watch the the tape directors once cut i is saw too it many on times dvd and and it there shows is people also who a know film turkish about plot the of consistency the from film reality making is\n",
            " Generating with temp 0.6\n",
            "This movie adaptation seemed of like a they play [UNK] too script drag and with was the poorly bad written the dialogue production the but characters the were sound badly stiff [UNK] and around the the most characters jolly [UNK] and out i this really was had left to down jump the\n",
            " Generating with temp 0.7\n",
            "This movie was is the horrible worst worst movie that want i [UNK] have an ever open seen fire perhaps no that such is thing by that evil ive only seen seen that on yes the we ending are this looking [UNK] to quaid make on you some have of even the\n",
            " Generating with temp 1.0\n",
            "This movie series is has totally a different weak experience cast than in the the paper onscreen known writing it directing is and fine typical too lowbudget and schlock well that paced as movie the giving plot it a as go quickly [UNK] as technology the and cutting fog we and find\n",
            " Generating with temp 1.5\n",
            "This movie movie is just outstanding mostly the [UNK] plot movie is takes how the the wrong successor movie jafar with [UNK] ellen one [UNK] of store my employees [UNK] along but with it far and it take succeeds it in is looking the for characters the to whole show pot it\n",
            "391/391 [==============================] - 170s 433ms/step - loss: 4.3146\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.2615 Generating with temp 0.2\n",
            "This movie animation has was a done very before poor the disney return picture home quality for and the the disney half studio way was through there the was story animation and was makes there weird had story to a be lot made to in come the to age the sound movie\n",
            " Generating with temp 0.5\n",
            "This movie would is not very worth well watching worth because it we is never just boring as boring boring as and you would are think just 10 so minutes minutes into of this my my life life have almost i nothing started to and close ends it in still reaching its\n",
            " Generating with temp 0.6\n",
            "This movie mockumentary was was simply unable boring to unbelievable do moment one what answer got not in to 1997 mention but at [UNK] that only a started film its festival an after interesting all [UNK] the reviews movie due has to jumped [UNK] around it john also [UNK] called and trouble\n",
            " Generating with temp 0.7\n",
            "This movie movie was was ahead set of in the which west for so some months good and part great 1 is the really exception exciting is and that the it special explicit to and me [UNK] often or through more but or did less these with images what from was the\n",
            " Generating with temp 1.0\n",
            "This movie movie is tries no to more make of sense anything from thats the typical point teen of slasher getting meets [UNK] gold failed meanwhile but a does car not crash make we sense might and feel want that to of journalist the ali gang [UNK] members [UNK] [UNK] [UNK] [UNK]\n",
            " Generating with temp 1.5\n",
            "This movie show surpasses can the be point done i by was that all it the has way some of real the relevance actors admittedly and especially some kind kids of that [UNK] they grew had around a and time i relating found to them that to the be very educational best\n",
            "391/391 [==============================] - 170s 433ms/step - loss: 4.2615\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.2174 Generating with temp 0.2\n",
            "This movie movie starts starts out off as to an showing 80s over game in of a the giant era robots you two will know go its from going one then day pick you up up liners until cool the meet action down is one repeated of scene three whether brothers theyre\n",
            " Generating with temp 0.5\n",
            "This movie movie is is a designed rather movie whitney the and movie since does the both beginning sides and of the the opera movie actors has do been a referred wear to leather in [UNK] jersey but doing the something whole that movie messes revolves rory around fairly janis ambitious [UNK]\n",
            " Generating with temp 0.6\n",
            "This movie morning highlights fox eddie keith murphys have riddle been role [UNK] by ii his night masterpiece apparently this there one is is [UNK] no of doubt either the public weak himself scripts hour or changes so doyle this id is rank a in positive the picture most and notably curious\n",
            " Generating with temp 0.7\n",
            "This movie animation is to tightly ninja used predecessors some as 70s set camp up vintage to crow powells play father and and son his are childhood the through suit the the droll rest plodding of performance this as truly an was outrageous big though budget deep actioner fox half bugs of\n",
            " Generating with temp 1.0\n",
            "This movie nostalgic is about like a news christmas supposed bus to driver man by a chance sappy and love overly its sentimental a and uncompromising subtle story first it the delivers story enough job to visual reveal comedy is during admittedly the bitten era knees the and viewer the knows mikes\n",
            " Generating with temp 1.5\n",
            "This movie via is a first typical rate latin drama class rather prosecutor than group a in community a for pair all of morocco tough [UNK] and lead tens to of plenty mercifully of students people led are by getting four shaky and years several later hundred on american to [UNK] a\n",
            "391/391 [==============================] - 170s 433ms/step - loss: 4.2174\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1800 Generating with temp 0.2\n",
            "This movie movie mostly is based based on upon the about king bettie of page sonja [UNK] [UNK] for she the follows role her of usual a [UNK] young autobiography actress most named important novel roles and here [UNK] its [UNK] a never [UNK] would in fit the into character the lucy\n",
            " Generating with temp 0.5\n",
            "This movie film is makes one you of wish my you problems had i just would [UNK] have it been on a a lot scale more teen of [UNK] college made days before in 30 polish or from so this i movie could that be cause so for loud this that movie\n",
            " Generating with temp 0.6\n",
            "This movie is is terrible best branagh movie is ever the in problem the its movie a a movie hired that in greg the [UNK] play to fairly an [UNK] argument exit which 1956 involves every the hindi credited sequel [UNK] which rebellion was and not also the directed acting by features\n",
            " Generating with temp 0.7\n",
            "This movie movie is is a something great that and pulls can it get off worse the the acting acting is has atrocious the but special [UNK] bad the bites bad dog guy goes he nuts is to just each [UNK] other  michael douglas did a great job of playing [UNK]\n",
            " Generating with temp 1.0\n",
            "This movie is is about a two man family who guy is who selected dead for thats freedom 10 in years a of point marriage of when his a hands boy feels is his a son great and take [UNK] on a the journey face of of is the becoming [UNK] a\n",
            " Generating with temp 1.5\n",
            "This movie movie is takes totally place into in a a country swedish where village a goes urban with loneliness an and [UNK] [UNK] course by in the the rarely french great take country the to director sit all through the the script entire is movie amazing has lets a you little\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.1800\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1481 Generating with temp 0.2\n",
            "This movie is was just annoying plain and think terrible that with elizabeth the having movie to alice quote in describe her it from showed that her irene cool tells rainbow us a nothing tale they around want her and to drowning teach in julie [UNK] annoy [UNK] you belle to is\n",
            " Generating with temp 0.5\n",
            "This movie is isnt pathetic worth the anyone wait spectacular for a a dinner minute is you a are mystery in lover the and relationship miraculously between breaks most the scenes jeopardy are the more best powerful unrealistic for and a rare good person decision they the played problem their with character\n",
            " Generating with temp 0.6\n",
            "This movie short has kind clichéd of song being its returning just from a hell movie of like two being exceptions expecting its her like typical most song of you the get power emotionally dancing sour thing [UNK] shes almost been even shaking worse stop when barbie they got win around my\n",
            " Generating with temp 0.7\n",
            "This movie week was challenges entertaining and to it be lots interesting of but classic it comedy has with a many good other scenery films nice but soundtrack that is is engaging plenty and of lots greek of stuff things and but the then rest there is is somewhere definitely between the\n",
            " Generating with temp 1.0\n",
            "This movie movie had turned tons into of the velvet middle stephen aged king olivia as disappointed herbert grease [UNK] as that is was my the favorite second its movie one for of awhile the i best think critics of would the be sheer right [UNK] instant kate will the explain same\n",
            " Generating with temp 1.5\n",
            "This movie is has refreshing some and great talented laughs actors i getting liked their to spouse them its but only thats colorful quite approach apart in from the finding mafia the change latest of punchline mary later kate appears is to just be dianne in keaton this seems movie a is\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.1481\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1199 Generating with temp 0.2\n",
            "This movie is would really be not about it the kill acting bill as a aunt dumb type teenage of female punishment charm trapped nudity in [UNK] a dont lot [UNK] of see bad it acting should and have be been unfaithful less unless than you i love could cary swallow meet\n",
            " Generating with temp 0.5\n",
            "This movie movie was has like a many kidnaps of 9 his million son dollars and needed hiding china in syndrome fact it his was wife just trying coming to out the the romanian money pretty whos how just a made country of in [UNK] the the scene bad by and telling\n",
            " Generating with temp 0.6\n",
            "This movie film is is a an top international ten classic without film a use good of name what stars is mr [UNK] [UNK] is is a so much [UNK] better in spent this that film it was works just [UNK] annoying of funny get all under the fire uk that are\n",
            " Generating with temp 0.7\n",
            "This movie was is widely about considered as i high would high have watched always older a films better or than less a survivors western in however spite it of was their the wonderfully second colorful another animated one movie at to the man end especially the after end seeing of the\n",
            " Generating with temp 1.0\n",
            "This movie movie was should so not low [UNK] enough as to it write as one for and the a two lot or of so the kissing reason scenes i that couldnt [UNK] sit a through father this in movie many until people the fell long asleep ago at not the given\n",
            " Generating with temp 1.5\n",
            "This movie is is a certainly terrible not movie one as and it the really desperation bad to acting the if plots youre were looking counting for as one a might very think very a interesting whole budget movie was would labeled really as stupid a thriller movie without and any i\n",
            "391/391 [==============================] - 170s 433ms/step - loss: 4.1199\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.0946 Generating with temp 0.2\n",
            "This movie is is [UNK] the propaganda story rarely of have colin i wilson really did did not not get have that any special invading attention government is forces worthy and of perhaps any the stupid most muscle unnatural [UNK] dialogue ever lacking the in characters the or [UNK] actress situations has\n",
            " Generating with temp 0.5\n",
            "This movie is has pure [UNK] gold crap [UNK] and make french it studios carlos tend [UNK] to it have the a greasy horrible hero film general that was belongs only on one the thing title i immediately find fell it asleep again in thats [UNK] ludicrous thats in what the has\n",
            " Generating with temp 0.6\n",
            "This movie is is much a more love adventurous story sex than greed a and self mansion righteous its fight of sequences course the may symbols be unlike prepared the for situation sonic and adventure youth and as thanks people home in this the is [UNK] enough clumsy to plot replay details\n",
            " Generating with temp 0.7\n",
            "This movie is has a a thrill good gone cast bound with in this the film lead just actors goes taking back over in without the breath flow sounding fresh exactly and the destroy story advances the all deliberate margaret side james of o this struggling movie genius or the just success\n",
            " Generating with temp 1.0\n",
            "This movie is has badly all written the and blue acted [UNK] films poorly with acted poor and dialogue even come the on effects end and of directing course were script awful the but [UNK] the character characters work had all all the its characters ambition not and even entertainment irritating nor\n",
            " Generating with temp 1.5\n",
            "This movie movie is must horrible be everyone filmed will it rent as in it horror people film cant is get pretentious details and like some your parts friends throw will themselves probably in be all [UNK] movies kings ever the however gorgeous if wonderful you character like is me in in\n",
            "391/391 [==============================] - 170s 433ms/step - loss: 4.0946\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.0721 Generating with temp 0.2\n",
            "This movie is is excellent just along in your the heart [UNK] of have paris seen if many you of really them want were to involved see in it the are cheesy both lines versions and and sort embarrassingly of photographed comedy very this beautiful movie film is is called virtually small\n",
            " Generating with temp 0.5\n",
            "This movie was is freaky absolutely having terrible time sequels mode squeeze a they [UNK] had and a their few [UNK] other before curious however what it the was plot familiar of in [UNK] the young original girl not played keen by and a turned drunk suddenly sequel its i like was\n",
            " Generating with temp 0.6\n",
            "This movie film could is be really one awful of movie the as cutting a of black this and film black might it get be very great funny and hot sad though as true is the the third [UNK] much begins to with fall a of girl a as naked she therapy\n",
            " Generating with temp 0.7\n",
            "This movie film is is one really of sad the faults most the about [UNK] those school who [UNK] are in heroes [UNK] and and [UNK] others tackle the their issue issues is and pretty how deep they it live is together a on troubled stage part until of they the have\n",
            " Generating with temp 1.0\n",
            "This movie movie isnt was as terrible atrocious as as has all yearold the school best girls one wrestling ever cartoon and characters perhaps on its the edge worst from of watching than to [UNK] begin your with favourite [UNK] includes that every said scene [UNK] the ah nameless i [UNK] use\n",
            " Generating with temp 1.5\n",
            "This movie was had horrible the shocked tape shocked ever is after the having fact read finished the it script just did did not the go movie to [UNK] good with novel all ideas the dont characters think were again moan [UNK] with on humor that and excited i over just [UNK]\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.0721\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.0521 Generating with temp 0.2\n",
            "This movie movie has is nothing filled to me women emotions i it need only to 10 understand minutes some of [UNK] done the andor womens disgusting background flashy music dialogues nothing real special good viking especially or compete some for men regular in shooting this women movie is is the beautiful\n",
            " Generating with temp 0.5\n",
            "This movie movie was is alright about but gambling that it held never around lets anything forget except it for was patrick originally elliott played family in guy the roles blond was character less during lame joel halfway andersons displays little real the wilson steel likable running character gag stages promoting an\n",
            " Generating with temp 0.6\n",
            "This movie one was of king those nominated kinds for of tv films creations that are give good this performances i but think can some be of fair the a story music is butcher harsh whos its just a way great to fun make the a characters point perfect if the you\n",
            " Generating with temp 0.7\n",
            "This movie movie is had funny more and ok drama not is m good serious but but none it is really very scary entertaining very throughout tense this atmosphere movie really made come up throughout with the a ending bit its were usually done about well soft lets porn go this i\n",
            " Generating with temp 1.0\n",
            "This movie is is definitely made worth by the adults summary if but you the are production used the to same shooting way for you starters dont they always do dont pure change gore the movies path of silly nature people cheap still in collect these bmovies arent starring that the would\n",
            " Generating with temp 1.5\n",
            "This movie was is so the boring average mostly havent just even been seen worth to sitting watch through bad john acting [UNK] mistakes is i bad should wooden say performances the in budget this their movie plot was is nonexistent very the poorly actors developed are while apparently you overdone can\n",
            "391/391 [==============================] - 171s 433ms/step - loss: 4.0521\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.0342 Generating with temp 0.2\n",
            "This movie show was had funny the moments acting to in the this dialogue show was had brought the up scifi i channel think and listening [UNK] to em the do [UNK] shatner hit as the jason [UNK] office it die stunk hard of and himself its it a didnt shame as\n",
            " Generating with temp 0.5\n",
            "This movie show is is not as on mocking a other below commentators average could in think the about paranoia itself and works robot i nail must to watch see it what like was space trying  to make itself a little complex by showing the atomic bomb things [UNK] information was\n",
            " Generating with temp 0.6\n",
            "This movie movie is really the great best characterizations movie and to the be viewer impressed to and watch insight tales i of thought course that a the movie movie was doesnt easy hurt except the that fact [UNK] it character to is be so offensive moving in like a you family\n",
            " Generating with temp 0.7\n",
            "This movie movie is has not a to good be movie called if a its friend a comparing movie to with clive r owen with then my [UNK] friend friend and for i her watched first it movie i im didnt a know big about culture it in the all movie public\n",
            " Generating with temp 1.0\n",
            "This movie magical started things an good interesting premise concept and even ended if up it with wasnt a 2 dominant it at was all the about dialogue child natural actors and and to very all well of made it [UNK] look character awkward is animal downright thatll pathetically do be it\n",
            " Generating with temp 1.5\n",
            "This movie movie is misses not and easy or it poorly is directed not with tense a feelgood bad film [UNK] but la this [UNK] no is strongest appropriate example and of so the many folks characters all get have fresh to out know of [UNK]  the only sequence on the\n",
            "391/391 [==============================] - 170s 434ms/step - loss: 4.0342\n",
            "Epoch 13/100\n",
            " 81/391 [=====>........................] - ETA: 2:09 - loss: 4.0192"
          ]
        }
      ],
      "source": [
        "model.fit(lm_dataset, epochs=100, callbacks=[text_gen_callback])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "8a59fa574207f894b3e9ad9500f3af7c3da915e85a7dc0886d7b8cb1d26aaebb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
