{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 12:42:46.593380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-03 12:42:48.165339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lucas/miniconda3/lib/\n",
      "2022-12-03 12:42:48.165457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lucas/miniconda3/lib/\n",
      "2022-12-03 12:42:48.165468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recognize GPU\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download dataset (do only once)\n",
    "#!ls -lha kaggle.json\n",
    "#%pip install -q kaggle\n",
    "#!mkdir -p ~/.kaggle\n",
    "#!cp kaggle.json ~/.kaggle/\n",
    "#!chmod 600 /root/.kaggle/kaggle.json\n",
    "#!kaggle datasets download -d datasnaek/chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip\n",
    "#!unzip chess.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format data\n",
    "text_file = \"games.csv\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "movesarr = []\n",
    "\n",
    "for line in lines:\n",
    "    moves = line.split(\",\")\n",
    "    movesarr.append(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e4 e5 Nf3 Nc6 Nc3 Nf6 Bc4 Bb4 Ng5 d5 exd5 Nd4 d6 Ne6 dxc7 Qxc7 Bxe6 fxe6 O-O O-O Nce4 Nxe4 Nxe4 Qc6 Re1 Rf4 Ng3 Rg4 c3 Bc5 Qxg4 b5 Rxe5 Bb7 Qxe6+ Qxe6 Rxe6 Rf8 d4 Bb6 b3 b4 cxb4 Bxd4 Rb1 Bxf2+ Kh1 Bd5 Re5 Ba8 Be3 Rf3 Bxf2 Rxf2 Re8+ Rf8 Rxf8+ Kxf8 Rc1 Ke7 Rc7+ Kd6 Rxa7'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at random game\n",
    "import random\n",
    "\n",
    "movesarr[random.randint(0, len(movesarr) -1)][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out too low elo games\n",
    "moveseq = []\n",
    "\n",
    "for i in range(len(movesarr) -1): #Minus one because not looking at header in start\n",
    "    if int(movesarr[i +1][9]) > 1750: #Do plus one because don't look at header\n",
    "        moveseq.append(movesarr[i][12])\n",
    "        \n",
    "len(moveseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make function to retrieve game sequence array easily\n",
    "def getgame(num, seq):\n",
    "    if not seq:\n",
    "        return moveseq[num]\n",
    "    else:\n",
    "        return moveseq[num].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):\n",
    "\n",
    "    # initialize an empty string\n",
    "    str1 = \"\"\n",
    "\n",
    "    # traverse in the string\n",
    "    for ele in s:\n",
    "        if ele == s[-1]:\n",
    "            str1 += f\"{ele}\"\n",
    "        else:\n",
    "            str1 += f\"{ele} \"\n",
    " \n",
    "    # return string\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "segmented = []\n",
    "for p in range(5):\n",
    "    for i in range(len(getgame(p, True))):\n",
    "        if i +1 != len(getgame(p, True)):\n",
    "            segmented.append((f\"{listToString(getgame(0, True)[:i +1])}\", f\"[start] {listToString(getgame(0, True)[i+1:i +2])} [end]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "segmented = []\n",
    "\n",
    "for p in range(len(moveseq)):\n",
    "    i = random.randrange(0, len(getgame(p, True)))\n",
    "    segmented.append((f\"{listToString(getgame(0, True)[:i +1])}\", f\"[start] {listToString(getgame(0, True)[i+1:i +2])} [end]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d4 d5 Nc3 Nf6 Bf4', '[start] Bf5 [end]')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n",
      "4024\n",
      "861\n"
     ]
    }
   ],
   "source": [
    "#Partition data\n",
    "import random\n",
    "random.shuffle(segmented)\n",
    "\n",
    "num_val_samples = int(0.15 * len(segmented))\n",
    "num_train_samples = len(segmented) - 2*num_val_samples\n",
    "train_samp = segmented[:num_train_samples]\n",
    "val_samp = segmented[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_samp = segmented[num_train_samples + num_val_samples:]\n",
    "\n",
    "## of samples for each category\n",
    "print(num_val_samples)\n",
    "print(num_train_samples)\n",
    "print(len(test_samp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 12:42:50.089386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-03 12:42:52.207922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 106 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-12-03 12:42:52.253940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 106.56M (111738880 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-12-03 12:42:52.254559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 95.91M (100564992 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    return tf.strings.lower(input_string)\n",
    "\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize = custom_standardization\n",
    ")\n",
    "train_start_texts = [pair[0] for pair in train_samp]\n",
    "train_end_texts = [pair[1] for pair in train_samp]\n",
    "source_vectorization.adapt(train_start_texts)\n",
    "target_vectorization.adapt(train_end_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1],\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_samp)\n",
    "val_ds = make_dataset(val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 20)\n",
      "inputs['spanish'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 12:42:55.717554: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embed_dim = 256\n",
    "latent_dim = 1024\n",
    "\n",
    "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = layers.Bidirectional(\n",
    "    layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 12:43:29.141586: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 14.65MiB (rounded to 15360000)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-03 12:43:29.141627: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-03 12:43:29.141648: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 20, Chunks in use: 20. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 141B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141667: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141684: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141700: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141716: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141731: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141750: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 2, Chunks in use: 2. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141767: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141784: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141801: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141818: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141833: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141846: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141861: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 2. 8.98MiB allocated for chunks. 6.00MiB in use in bin. 6.00MiB client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141874: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 0. 5.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141890: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 2. 28.94MiB allocated for chunks. 28.94MiB in use in bin. 26.65MiB client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141905: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 3. 62.61MiB allocated for chunks. 62.61MiB in use in bin. 41.30MiB client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141918: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141930: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141942: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141954: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-03 12:43:29.141968: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 14.65MiB was 8.00MiB, Chunk State: \n",
      "2022-12-03 12:43:29.141980: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 21230336\n",
      "2022-12-03 12:43:29.141995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6ce2000000 of size 21230336 next 18446744073709551615\n",
      "2022-12-03 12:43:29.142006: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 90508544\n",
      "2022-12-03 12:43:29.142017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000000 of size 1280 next 1\n",
      "2022-12-03 12:43:29.142028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000500 of size 256 next 2\n",
      "2022-12-03 12:43:29.142044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000600 of size 256 next 3\n",
      "2022-12-03 12:43:29.142056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000700 of size 256 next 4\n",
      "2022-12-03 12:43:29.142066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000800 of size 256 next 5\n",
      "2022-12-03 12:43:29.142077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000900 of size 256 next 6\n",
      "2022-12-03 12:43:29.142087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000a00 of size 256 next 7\n",
      "2022-12-03 12:43:29.142098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000b00 of size 768 next 8\n",
      "2022-12-03 12:43:29.142108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a000e00 of size 512 next 9\n",
      "2022-12-03 12:43:29.142119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001000 of size 256 next 10\n",
      "2022-12-03 12:43:29.142129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001100 of size 256 next 11\n",
      "2022-12-03 12:43:29.142144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001200 of size 256 next 12\n",
      "2022-12-03 12:43:29.142155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001300 of size 256 next 13\n",
      "2022-12-03 12:43:29.142165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001400 of size 256 next 14\n",
      "2022-12-03 12:43:29.142176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001500 of size 256 next 16\n",
      "2022-12-03 12:43:29.142186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001600 of size 256 next 17\n",
      "2022-12-03 12:43:29.142196: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001700 of size 256 next 18\n",
      "2022-12-03 12:43:29.142207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001800 of size 256 next 21\n",
      "2022-12-03 12:43:29.142217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001900 of size 256 next 26\n",
      "2022-12-03 12:43:29.142228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a001a00 of size 24576 next 25\n",
      "2022-12-03 12:43:29.142240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f6d2a007a00 of size 6266880 next 23\n",
      "2022-12-03 12:43:29.142251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a601a00 of size 3145728 next 24\n",
      "2022-12-03 12:43:29.142261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a901a00 of size 24576 next 27\n",
      "2022-12-03 12:43:29.142271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a907a00 of size 256 next 28\n",
      "2022-12-03 12:43:29.142284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a907b00 of size 256 next 22\n",
      "2022-12-03 12:43:29.142298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a907c00 of size 256 next 31\n",
      "2022-12-03 12:43:29.142311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2a907d00 of size 256 next 33\n",
      "2022-12-03 12:43:29.142325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f6d2a907e00 of size 3120384 next 29\n",
      "2022-12-03 12:43:29.142343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2ac01b00 of size 3145728 next 30\n",
      "2022-12-03 12:43:29.142357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2af01b00 of size 14990592 next 19\n",
      "2022-12-03 12:43:29.142372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2bd4d800 of size 15360000 next 20\n",
      "2022-12-03 12:43:29.142387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2cbf3800 of size 25169920 next 15\n",
      "2022-12-03 12:43:29.142403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f6d2e3f4800 of size 19252480 next 18446744073709551615\n",
      "2022-12-03 12:43:29.142416: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2022-12-03 12:43:29.142435: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 20 Chunks of size 256 totalling 5.0KiB\n",
      "2022-12-03 12:43:29.142450: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 512 totalling 512B\n",
      "2022-12-03 12:43:29.142466: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 768 totalling 768B\n",
      "2022-12-03 12:43:29.142481: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-03 12:43:29.142498: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 24576 totalling 48.0KiB\n",
      "2022-12-03 12:43:29.142519: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 3145728 totalling 6.00MiB\n",
      "2022-12-03 12:43:29.142535: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14990592 totalling 14.30MiB\n",
      "2022-12-03 12:43:29.142551: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15360000 totalling 14.65MiB\n",
      "2022-12-03 12:43:29.142567: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 19252480 totalling 18.36MiB\n",
      "2022-12-03 12:43:29.142584: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 21230336 totalling 20.25MiB\n",
      "2022-12-03 12:43:29.142609: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 25169920 totalling 24.00MiB\n",
      "2022-12-03 12:43:29.142624: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 97.61MiB\n",
      "2022-12-03 12:43:29.142638: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 111738880 memory_limit_: 111738880 available bytes: 0 curr_region_allocation_bytes_: 446955520\n",
      "2022-12-03 12:43:29.142666: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                       111738880\n",
      "InUse:                       102351616\n",
      "MaxInUse:                    102351616\n",
      "NumAllocs:                         584\n",
      "MaxAllocSize:                 25169920\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-03 12:43:29.142685: W tensorflow/tsl/framework/bfc_allocator.cc:492] **************xxxx**____****__***************x****************************xxxxxxxx*************xxxxx\n",
      "2022-12-03 12:43:29.142720: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[15000,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[15000,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m past_target \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m,), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mspanish\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mEmbedding(vocab_size, embed_dim, mask_zero\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)(past_target)\n\u001b[1;32m      3\u001b[0m decoder_gru \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mGRU(latent_dim, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m x \u001b[39m=\u001b[39m decoder_gru(x, initial_state\u001b[39m=\u001b[39mencoded_source)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[1;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[1;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[1;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   2106\u001b[0m     )\n\u001b[1;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[15000,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 12:40:42.709925: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 61440000 exceeds 10% of free system memory.\n",
      "2022-12-03 12:40:49.257005: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 61440000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/63 [..............................] - ETA: 4:43 - loss: 9.5956 - accuracy: 0.3022     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39mone.keras\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      6\u001b[0m seq2seq_rnn\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],)\n\u001b[0;32m---> 10\u001b[0m seq2seq_rnn\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_ds, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"one.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "seq2seq_rnn.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],)\n",
    "seq2seq_rnn.fit(train_ds, epochs=2, validation_data=val_ds, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a59fa574207f894b3e9ad9500f3af7c3da915e85a7dc0886d7b8cb1d26aaebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
